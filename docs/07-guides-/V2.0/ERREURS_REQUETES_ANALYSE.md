# Analyse des Erreurs de RequÃªte AETHERFLOW

**Date** : 26 janvier 2025

---

## ğŸ” Types d'Erreurs "Request error"

Les erreurs `RequestError` dans httpx sont des erreurs de base qui englobent plusieurs types d'erreurs rÃ©seau et de timeout.

### HiÃ©rarchie des Exceptions httpx

```
RequestError (base class)
â”œâ”€â”€ TimeoutException
â”‚   â”œâ”€â”€ ConnectTimeout - Ã‰chec Ã©tablissement connexion
â”‚   â”œâ”€â”€ ReadTimeout - Ã‰chec rÃ©ception donnÃ©es
â”‚   â”œâ”€â”€ WriteTimeout - Ã‰chec envoi donnÃ©es
â”‚   â””â”€â”€ PoolTimeout - Ã‰chec acquisition connexion du pool
â””â”€â”€ NetworkError
    â”œâ”€â”€ ConnectError - Ã‰chec Ã©tablissement connexion
    â”œâ”€â”€ ReadError - Ã‰chec rÃ©ception donnÃ©es
    â””â”€â”€ WriteError - Ã‰chec envoi donnÃ©es
```

---

## ğŸ¯ Causes Probables dans notre Cas

### 1. **Timeout de Connexion (ConnectTimeout)**

**SymptÃ´mes** :
- Erreur aprÃ¨s ~60 secondes (timeout configurÃ©)
- Les deux requÃªtes en parallÃ¨le Ã©chouent simultanÃ©ment

**Causes possibles** :
- **API DeepSeek surchargÃ©e** : Trop de requÃªtes simultanÃ©es
- **ProblÃ¨me rÃ©seau temporaire** : Latence Ã©levÃ©e, paquets perdus
- **Rate limiting cÃ´tÃ© API** : L'API refuse les connexions temporairement
- **Timeout trop court** : 60s peut Ãªtre insuffisant pour certaines requÃªtes longues

**Solution actuelle** :
- âœ… Retry automatique avec backoff exponentiel (2^attempt secondes)
- âœ… Les retries ont rÃ©ussi dans notre cas (step_2 et step_3 ont finalement rÃ©ussi)

---

### 2. **Rate Limiting de l'API**

**SymptÃ´mes** :
- Erreurs simultanÃ©es sur plusieurs requÃªtes parallÃ¨les
- Erreurs aprÃ¨s ~1 minute (timeout avant que le rate limit soit clair)

**Causes** :
- **Limite de requÃªtes par minute** : DeepSeek peut limiter le nombre de requÃªtes
- **Limite de requÃªtes simultanÃ©es** : L'API peut limiter les connexions parallÃ¨les
- **Quota dÃ©passÃ©** : Limite mensuelle/quota atteint

**Solution actuelle** :
- âœ… Le code dÃ©tecte les erreurs 429 (rate limit) et attend avant retry
- âš ï¸ Mais les RequestError peuvent masquer les erreurs 429 si timeout avant rÃ©ponse

---

### 3. **ProblÃ¨mes RÃ©seau Temporaires**

**SymptÃ´mes** :
- Erreurs intermittentes
- Erreurs sur plusieurs requÃªtes simultanÃ©es

**Causes** :
- **InstabilitÃ© rÃ©seau** : Connexion internet instable
- **DNS resolution** : ProblÃ¨me de rÃ©solution DNS temporaire
- **Firewall/Proxy** : Blocage temporaire des connexions
- **ProblÃ¨me cÃ´tÃ© serveur DeepSeek** : Maintenance ou problÃ¨me infrastructure

**Solution actuelle** :
- âœ… Retry automatique avec backoff exponentiel
- âœ… Les retries permettent de contourner les problÃ¨mes temporaires

---

### 4. **Connexions ParallÃ¨les**

**SymptÃ´mes** :
- Les deux requÃªtes en parallÃ¨le Ã©chouent simultanÃ©ment
- Une seule requÃªte rÃ©ussit gÃ©nÃ©ralement

**Causes** :
- **Limite de connexions simultanÃ©es** : L'API peut limiter les connexions parallÃ¨les
- **Pool de connexions Ã©puisÃ©** : httpx peut avoir des limites sur le pool
- **Conflit de ressources** : Partage de ressources entre requÃªtes parallÃ¨les

**Observation** :
- Dans notre cas, les deux requÃªtes (step_2 et step_3) ont Ã©chouÃ© simultanÃ©ment
- Mais les retries ont rÃ©ussi, suggÃ©rant un problÃ¨me temporaire plutÃ´t qu'une limite structurelle

---

## ğŸ“Š Analyse de notre Cas Concret

### ScÃ©nario ObservÃ©

```
09:33:14 - DÃ©marrage step_2 et step_3 en parallÃ¨le
09:34:15 - Les deux Ã©chouent avec "Request error" (aprÃ¨s ~60s)
09:35:22 - step_3 rÃ©ussit aprÃ¨s retry (128s total)
09:35:40 - step_2 rÃ©ussit aprÃ¨s retry (146s total)
```

### InterprÃ©tation

1. **Timeout probable** : Les deux requÃªtes ont timeout aprÃ¨s ~60s (timeout configurÃ©)
2. **ProblÃ¨me temporaire** : Les retries ont rÃ©ussi, indiquant un problÃ¨me temporaire
3. **Pas de limite structurelle** : Les requÃªtes ont finalement rÃ©ussi

### Causes Probables (par ordre)

1. **API DeepSeek temporairement surchargÃ©e** (70%)
   - Trop de requÃªtes simultanÃ©es
   - Rate limiting temporaire
   - Latence Ã©levÃ©e cÃ´tÃ© serveur

2. **Timeout trop court pour requÃªtes longues** (20%)
   - 60s peut Ãªtre insuffisant pour gÃ©nÃ©rer 2000-2500 tokens
   - Les requÃªtes prennent du temps Ã  gÃ©nÃ©rer

3. **ProblÃ¨me rÃ©seau temporaire** (10%)
   - InstabilitÃ© rÃ©seau
   - ProblÃ¨me DNS temporaire

---

## ğŸ”§ Solutions et AmÃ©liorations Possibles

### 1. Augmenter le Timeout

**Actuel** : 60 secondes
**RecommandÃ©** : 120-180 secondes pour requÃªtes longues

```python
# Backend/Prod/config/settings.py
timeout: int = Field(
    default=120,  # AugmentÃ© de 60 Ã  120
    alias="TIMEOUT",
    description="Request timeout in seconds"
)
```

### 2. AmÃ©liorer la Gestion des Erreurs

**Actuel** : `RequestError` gÃ©nÃ©rique
**AmÃ©lioration** : DÃ©tecter le type spÃ©cifique d'erreur

```python
except httpx.ConnectTimeout:
    # Timeout de connexion - retry avec backoff plus long
    wait_time = 5 * (2 ** attempt)
except httpx.ReadTimeout:
    # Timeout de lecture - requÃªte trop longue, augmenter timeout
    # ou diviser la requÃªte
except httpx.ConnectError:
    # Erreur de connexion - problÃ¨me rÃ©seau, retry normal
```

### 3. Limiter les RequÃªtes ParallÃ¨les

**Actuel** : Toutes les Ã©tapes indÃ©pendantes en parallÃ¨le
**AmÃ©lioration** : Limiter Ã  2-3 requÃªtes simultanÃ©es par provider

```python
# Semaphore pour limiter les requÃªtes parallÃ¨les
semaphore = asyncio.Semaphore(2)  # Max 2 requÃªtes simultanÃ©es

async def _execute_step_with_monitoring(...):
    async with semaphore:
        # ExÃ©cuter la requÃªte
```

### 4. AmÃ©liorer les Logs

**Actuel** : "Request error: {str(e)}"
**AmÃ©lioration** : Logs plus dÃ©taillÃ©s

```python
except httpx.RequestError as e:
    error_type = type(e).__name__
    error_details = {
        "type": error_type,
        "message": str(e),
        "url": self.api_url,
        "attempt": attempt + 1
    }
    logger.warning(f"Request error ({error_type}): {error_details}")
```

---

## âœ… Ce qui Fonctionne DÃ©jÃ 

1. **Retry automatique** : âœ… Fonctionne (les requÃªtes ont rÃ©ussi aprÃ¨s retry)
2. **Backoff exponentiel** : âœ… Fonctionne (2^attempt secondes d'attente)
3. **Gestion des erreurs** : âœ… Les erreurs sont capturÃ©es et retryÃ©es
4. **ParallÃ©lisation** : âœ… Fonctionne (les deux Ã©tapes ont finalement rÃ©ussi)

---

## ğŸ“‹ Recommandations

### Court Terme

1. **Augmenter le timeout** Ã  120-180 secondes
2. **AmÃ©liorer les logs** pour mieux diagnostiquer les erreurs
3. **Surveiller les patterns** : Si les erreurs se rÃ©pÃ¨tent, investiguer

### Moyen Terme

1. **Limiter les requÃªtes parallÃ¨les** par provider (semaphore)
2. **DÃ©tecter les types d'erreurs spÃ©cifiques** pour adapter la stratÃ©gie
3. **Ajouter des mÃ©triques** : Taux d'erreur, temps moyen de retry

### Long Terme

1. **Circuit breaker** : ArrÃªter les requÃªtes si trop d'erreurs
2. **Fallback providers** : Utiliser un autre provider si un Ã©choue
3. **Queue system** : Mettre en queue les requÃªtes si API surchargÃ©e

---

## ğŸ¯ Conclusion

**Les erreurs "Request error" dans notre cas sont probablement dues Ã ** :
1. **API DeepSeek temporairement surchargÃ©e** (cause principale)
2. **Timeout de 60s peut-Ãªtre trop court** pour certaines requÃªtes longues
3. **ProblÃ¨me rÃ©seau temporaire** (moins probable)

**Le systÃ¨me de retry fonctionne bien** : Les requÃªtes ont finalement rÃ©ussi aprÃ¨s retry, ce qui montre que le problÃ¨me Ã©tait temporaire et que la stratÃ©gie de retry est efficace.

**Recommandation principale** : Augmenter le timeout Ã  120-180 secondes pour rÃ©duire les erreurs de timeout.

---

**DerniÃ¨re mise Ã  jour** : 26 janvier 2025
