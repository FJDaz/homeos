{
  "operations": [
    {
      "type": "modify_method",
      "target": "Orchestrator._execute_batch_parallel",
      "position": "after",
      "after_method": "__init__",
      "code": "    async def _execute_batch_parallel(\n        self,\n        batch: List[Step],\n        context: Optional[str],\n        results: Dict[str, StepResult]\n    ) -> None:\n        \"\"\"\n        Execute multiple independent steps in parallel using asyncio.gather().\n\n        If sequential_mode is enabled, execute steps one by one with a pause between them.\n        If file conflicts are detected (same file targeted by multiple steps), force sequential execution.\n\n        Args:\n            batch: List of steps to execute in parallel\n            context: Additional context for all steps\n            results: Dictionary to store step results\n        \"\"\"\n        # Check for file conflicts before execution\n        file_conflict_detected = False\n        conflict_details = []\n        \n        if len(batch) > 1 and not self.sequential_mode:\n            # Collect all target files from each step\n            all_target_files = {}\n            for step in batch:\n                if step.context and isinstance(step.context, dict):\n                    files = step.context.get('files', [])\n                    for file_path in files:\n                        # Normalize path for comparison\n                        normalized_path = str(Path(file_path).resolve())\n                        if normalized_path in all_target_files:\n                            # Conflict detected: same file targeted by multiple steps\n                            file_conflict_detected = True\n                            conflict_details.append({\n                                'file': normalized_path,\n                                'step1': all_target_files[normalized_path],\n                                'step2': step.id\n                            })\n                        else:\n                            all_target_files[normalized_path] = step.id\n            \n            if file_conflict_detected:\n                logger.warning(f\"‚ö†Ô∏è File conflict detected in batch of {len(batch)} steps\")\n                for conflict in conflict_details:\n                    logger.warning(f\"  File '{conflict['file']}' targeted by steps: {conflict['step1']}, {conflict['step2']}\")\n                logger.warning(\"üîÑ Forcing sequential execution to avoid file corruption\")\n                \n                # Temporarily enable sequential mode for this batch\n                original_sequential_mode = self.sequential_mode\n                self.sequential_mode = True\n                \n                try:\n                    # Execute steps sequentially\n                    step_results = []\n                    for i, step in enumerate(batch, 1):\n                        logger.info(f\"üìç Step {i}/{len(batch)}: {step.id}\")\n                        try:\n                            await self._execute_step_with_monitoring(step, context, results)\n                            step_results.append(None)  # Success (result already in dict)\n                        except Exception as e:\n                            logger.error(f\"Step {step.id} failed: {e}\")\n                            step_results.append(e)\n\n                        # Pause between steps to avoid rate limiting\n                        if i < len(batch):\n                            logger.info(\"‚è∏Ô∏è  Pausing 2s before next step...\")\n                            await asyncio.sleep(2)\n                    \n                    # Process results and handle errors\n                    for step, result in zip(batch, step_results):\n                        if isinstance(result, Exception):\n                            logger.error(f\"Unexpected error executing step {step.id}: {result}\")\n                            # Create failed result\n                            failed_result = StepResult(\n                                step_id=step.id,\n                                success=False,\n                                output=\"\",\n                                tokens_used=0,\n                                input_tokens=0,\n                                output_tokens=0,\n                                execution_time_ms=0,\n                                error=str(result)\n                            )\n                            results[step.id] = failed_result\n                            self.metrics.record_step_result(step, failed_result)\n                            \n                            # Update monitor\n                            self.monitor.complete_step(\n                                step.id,\n                                False,\n                                0.0,\n                                0,\n                                0.0,\n                                str(result)\n                            )\n                        else:\n                            # Result is already stored in results dict by _execute_step_with_monitoring\n                            if result.success:\n                                logger.info(f\"‚úì Step {step.id} completed successfully\")\n                            else:\n                                logger.error(f\"‚úó Step {step.id} failed: {result.error}\")\n                    \n                    return  # Exit early, batch already handled\n                finally:\n                    # Restore original sequential mode\n                    self.sequential_mode = original_sequential_mode\n        \n        # Continue with normal execution (no conflicts or sequential mode already enabled)\n        if self.sequential_mode:\n            logger.info(f\"üîÑ SEQUENTIAL MODE: Executing {len(batch)} steps ONE AT A TIME\")\n            step_results = []\n            for i, step in enumerate(batch, 1):\n                logger.info(f\"üìç Step {i}/{len(batch)}: {step.id}\")\n                try:\n                    await self._execute_step_with_monitoring(step, context, results)\n                    step_results.append(None)  # Success (result already in dict)\n                except Exception as e:\n                    logger.error(f\"Step {step.id} failed: {e}\")\n                    step_results.append(e)\n\n                # Pause between steps to avoid rate limiting\n                if i < len(batch):\n                    logger.info(\"‚è∏Ô∏è  Pausing 2s before next step...\")\n                    await asyncio.sleep(2)\n        else:\n            logger.info(f\"Executing {len(batch)} steps in parallel\")\n\n            # Create async tasks for each step\n            tasks = [\n                self._execute_step_with_monitoring(step, context, results)\n                for step in batch\n            ]\n\n            # Execute all steps in parallel with asyncio.gather\n            # return_exceptions=True allows other steps to continue if one fails\n            step_results = await asyncio.gather(*tasks, return_exceptions=True)\n        \n        # Process results and handle errors\n        for step, result in zip(batch, step_results):\n            if isinstance(result, Exception):\n                logger.error(f\"Unexpected error executing step {step.id}: {result}\")\n                # Create failed result\n                failed_result = StepResult(\n                    step_id=step.id,\n                    success=False,\n                    output=\"\",\n                    tokens_used=0,\n                    input_tokens=0,\n                    output_tokens=0,\n                    execution_time_ms=0,\n                    error=str(result)\n                )\n                results[step.id] = failed_result\n                self.metrics.record_step_result(step, failed_result)\n                \n                # Update monitor\n                self.monitor.complete_step(\n                    step.id,\n                    False,\n                    0.0,\n                    0,\n                    0.0,\n                    str(result)\n                )\n            else:\n                # Result is already stored in results dict by _execute_step_with_monitoring\n                if result.success:\n                    logger.info(f\"‚úì Step {step.id} completed successfully\")\n                else:\n                    logger.error(f\"‚úó Step {step.id} failed: {result.error}\")"
    }
  ]
}