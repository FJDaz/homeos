"""Orchestrator for executing AetherFlow plans."""
import asyncio
import json
import time
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple
from loguru import logger

# #region agent log
_DEBUG_LOG = "/Users/francois-jeandazin/AETHERFLOW/.cursor/debug.log"
def _dbg(hy: str, loc: str, msg: str, data: Optional[Dict] = None):
    with open(_DEBUG_LOG, "a") as f:
        f.write(json.dumps({"timestamp": int(time.time() * 1000), "hypothesisId": hy, "location": loc, "message": msg, "data": data or {}, "sessionId": "debug-session"}) + "\n")
# #endregion

from .models.plan_reader import PlanReader, Plan, Step, PlanValidationError
from .models.deepseek_client import StepResult
from .models.agent_router import AgentRouter
from .models.metrics import MetricsCollector
from .models.claude_validator import ClaudeCodeValidator
from .models.execution_monitor import ExecutionMonitor
from .config.settings import settings
from .rag import PageIndexRetriever
from .core.surgical_editor import SurgicalEditor
from .core.plan_status import update_plan_status
from .claude_helper import split_structure_and_code
from .ui.hybrid_loader import HybridLoader, Phase, StepStatus


class ExecutionError(Exception):
    """Raised when execution fails."""
    pass


class Orchestrator:
    """Orchestrates plan execution using AgentRouter (multi-provider support)."""

    def __init__(
        self,
        plan_reader: Optional[PlanReader] = None,
        agent_router: Optional[AgentRouter] = None,
        claude_validator: Optional[ClaudeCodeValidator] = None,
        rag_enabled: bool = True,
        execution_mode: str = "BUILD",
        enable_hybrid_loader: bool = True,
        sequential_mode: bool = False
    ):
        """
        Initialize orchestrator.

        Args:
            plan_reader: PlanReader instance (creates new if None)
            agent_router: AgentRouter instance (creates new if None)
            claude_validator: ClaudeValidator instance (creates new if None)
            rag_enabled: Whether to enable RAG for context enrichment (default True)
            execution_mode: Execution mode (FAST, BUILD, DOUBLE-CHECK)
        """
        self.plan_reader = plan_reader or PlanReader()
        self.execution_mode = execution_mode.upper()
        self.sequential_mode = sequential_mode
        # Initialize AgentRouter with prompt cache, semantic cache, and execution mode
        from .cache import PromptCache, SemanticCache
        prompt_cache = PromptCache()
        semantic_cache = SemanticCache()
        self.agent_router = agent_router or AgentRouter(
            prompt_cache=prompt_cache,
            semantic_cache=semantic_cache,
            execution_mode=self.execution_mode
        )
        self.claude_validator = claude_validator or ClaudeCodeValidator()
        self.metrics: Optional[MetricsCollector] = None
        self.monitor: Optional[ExecutionMonitor] = None
        self.enable_hybrid_loader = enable_hybrid_loader
        self.hybrid_loader: Optional[HybridLoader] = None

        # Rate limiting: semaphores per provider to limit concurrent requests
        # Limits: DeepSeek=5, Groq=10, Gemini=10, Codestral=5
        self._provider_semaphores = {
            "deepseek": asyncio.Semaphore(5),
            "groq": asyncio.Semaphore(10),
            "gemini": asyncio.Semaphore(10),
            "codestral": asyncio.Semaphore(5)
        }
        
        # Initialize RAG system
        self.rag_enabled = rag_enabled
        if self.rag_enabled:
            try:
                self.rag = PageIndexRetriever(use_embeddings=False)
                if self.rag.enabled:
                    logger.info("RAG system initialized for context enrichment")
                else:
                    logger.warning("RAG system disabled (LlamaIndex not available)")
                    self.rag_enabled = False
            except Exception as e:
                logger.warning(f"Failed to initialize RAG system: {e}")
                self.rag_enabled = False
                self.rag = None
        else:
            self.rag = None
    
    async def execute_plan(
        self,
        plan_path: Path,
        output_dir: Optional[Path] = None,
        context: Optional[str] = None,
        use_streaming: bool = False,
        execution_mode: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Execute a plan from a JSON file.
        
        Args:
            plan_path: Path to plan JSON file
            output_dir: Directory for output files (defaults to settings)
            context: Additional context for all steps
            use_streaming: If True, use streaming mode to start execution as soon as steps are available
            execution_mode: Execution mode (FAST, BUILD, DOUBLE-CHECK). Overrides instance default.
            
        Returns:
            Dictionary with execution results and metrics
            
        Raises:
            ExecutionError: If execution fails
        """
        # Update execution mode if provided
        if execution_mode:
            self.execution_mode = execution_mode.upper()
            self.agent_router.execution_mode = self.execution_mode
        
        if use_streaming:
            return await self._execute_plan_streaming(plan_path, output_dir, context)
        
        # Read and validate plan
        try:
            plan = self.plan_reader.read(plan_path)
        except PlanValidationError as e:
            raise ExecutionError(f"Plan validation failed: {e}")
        except FileNotFoundError as e:
            raise ExecutionError(f"Plan file not found: {e}")
        
        logger.info(f"Starting execution of plan {plan.task_id}")
        logger.info(f"Plan description: {plan.description}")
        logger.info(f"Total steps: {len(plan.steps)}")
        
        # Initialize RAG references (used in return statement)
        rag_references = []
        
        # Enrich context with RAG if enabled
        enriched_context = context
        if self.rag_enabled and self.rag and self.rag.enabled:
            try:
                rag_query = f"{plan.description}. {context or ''}"
                rag_results = await self.rag.retrieve(rag_query, history=[], top_k=3)
                if rag_results:
                    rag_context_parts = []
                    for result in rag_results:
                        rag_context_parts.append(f"[{result['reference']}]\n{result['content'][:500]}")
                        rag_references.append(result['reference'])
                    rag_context = "\n\n".join(rag_context_parts)
                    enriched_context = f"Contexte projet (RAG):\n{rag_context}\n\n{context or ''}"
                    logger.info(f"Context enriched with RAG: {len(rag_results)} references")
            except Exception as e:
                logger.warning(f"RAG enrichment failed: {e}, using original context")
        
        # Initialize metrics collector
        self.metrics = MetricsCollector(plan)
        
        # Initialize execution monitor
        self.monitor = ExecutionMonitor(plan.description, len(plan.steps))
        for step in plan.steps:
            self.monitor.add_step(step.id, step.description, step.type, step.complexity)
        self.monitor.start_monitoring()
        
        # Get execution order (respecting dependencies)
        execution_order = plan.get_execution_order()
        
        logger.info(f"Execution order: {len(execution_order)} batches")
        
        # Execute steps in order
        results: Dict[str, StepResult] = {}
        
        try:
            for batch_idx, batch in enumerate(execution_order, 1):
                logger.info(f"Executing batch {batch_idx}/{len(execution_order)} ({len(batch)} steps)")
                update_plan_status(
                    batch_index=batch_idx,
                    current_step_ids=[s.id for s in batch],
                    completed_steps=list(results.keys()),
                    total_steps=len(plan.steps),
                    total_batches=len(execution_order),
                )
                # #region agent log
                t_batch = time.time(); _dbg("D", "orchestrator:batch", "batch start", {"batch_idx": batch_idx, "n_batches": len(execution_order), "n_steps": len(batch), "step_ids": [s.id for s in batch]})
                # #endregion
                # Execute steps in batch (parallelized if multiple steps)
                if len(batch) > 1:
                    # Parallel execution for multiple independent steps
                    await self._execute_batch_parallel(batch, enriched_context, results)
                else:
                    # Sequential execution for single step
                    step = batch[0]
                    await self._execute_step_with_monitoring(step, enriched_context, results)
                # #region agent log
                _dbg("D", "orchestrator:batch", "batch end", {"batch_idx": batch_idx, "duration_s": round(time.time() - t_batch, 2)})
                # #endregion
        
        finally:
            # Stop monitoring
            if self.monitor:
                self.monitor.stop_monitoring()
                self.monitor.print_final_summary()
            
            # Finalize metrics
            self.metrics.finalize()
            
            # Export results
            if output_dir:
                output_dir = Path(output_dir)
                output_dir.mkdir(parents=True, exist_ok=True)
                
                # Save RAG references if available
                if rag_references:
                    rag_refs_file = output_dir / "rag_references.txt"
                    with open(rag_refs_file, 'w') as f:
                        f.write("RAG Context References:\n")
                        for ref in rag_references:
                            f.write(f"- {ref}\n")
                
                # Save step outputs
                self._save_step_outputs(output_dir, plan, results)
                
                # Export metrics
                metrics_json = output_dir / f"metrics_{plan.task_id}.json"
                metrics_csv = output_dir / f"metrics_{plan.task_id}.csv"
                self.metrics.export_json(metrics_json)
                self.metrics.export_csv(metrics_csv)
        
        # Print summary
        self.metrics.print_summary()
        
        # Return results
        plan_metrics = self.metrics.get_plan_metrics()
        
        # Get prompt cache stats
        cache_stats = None
        if self.agent_router.prompt_cache:
            cache_stats = self.agent_router.prompt_cache.get_cache_summary()
        
        return {
            "plan": plan,
            "results": results,
            "metrics": plan_metrics,
            "success": plan_metrics.success_rate == 1.0,
            "rag_enabled": self.rag_enabled,
            "rag_references": rag_references if self.rag_enabled else [],
            "prompt_cache_stats": cache_stats
        }
    
    async def _execute_batch_parallel(
        self,
        batch: List[Step],
        context: Optional[str],
        results: Dict[str, StepResult]
    ) -> None:
        """
        Execute multiple independent steps in parallel using asyncio.gather().

        If sequential_mode is enabled, execute steps one by one with a pause between them.
        If file conflicts are detected (same file targeted by multiple steps), force sequential execution.

        Args:
            batch: List of steps to execute in parallel
            context: Additional context for all steps
            results: Dictionary to store step results
        """
        file_conflict_detected, conflict_details = self._detect_file_conflicts(batch)

        if file_conflict_detected:
            logger.warning(f"‚ö†Ô∏è File conflict detected in batch of {len(batch)} steps")
            for conflict in conflict_details:
                logger.warning(f"  File '{conflict['file']}' targeted by steps: {conflict['step1']}, {conflict['step2']}")
            logger.warning("üîÑ Forcing sequential execution to avoid file corruption")
            await self._execute_batch_sequential(batch, context, results)
        else:
            if self.sequential_mode:
                logger.info(f"üîÑ SEQUENTIAL MODE: Executing {len(batch)} steps ONE AT A TIME")
                await self._execute_batch_sequential(batch, context, results)
            else:
                logger.info(f"Executing {len(batch)} steps in parallel")
                await self._execute_batch_concurrent(batch, context, results)
    
    def _detect_file_conflicts(self, batch: List[Step]) -> Tuple[bool, List[Dict[str, Any]]]:
        """
        Detect file conflicts in a batch of steps.

        Args:
            batch: List of steps to check for file conflicts

        Returns:
            Tuple: (file_conflict_detected, conflict_details)
        """
        file_conflict_detected = False
        conflict_details: List[Dict[str, Any]] = []
        all_target_files: Dict[str, str] = {}

        if len(batch) > 1:
            for step in batch:
                if step.context and isinstance(step.context, dict):
                    files = step.context.get('files', [])
                    for file_path in files:
                        # Normalize path for comparison
                        normalized_path = str(Path(file_path).resolve())
                        if normalized_path in all_target_files:
                            # Conflict detected: same file targeted by multiple steps
                            file_conflict_detected = True
                            conflict_details.append({
                                'file': normalized_path,
                                'step1': all_target_files[normalized_path],
                                'step2': step.id
                            })
                        else:
                            all_target_files[normalized_path] = step.id

        return file_conflict_detected, conflict_details
    
    async def _execute_batch_sequential(
        self,
        batch: List[Step],
        context: Optional[str],
        results: Dict[str, StepResult]
    ) -> None:
        """
        Execute a batch of steps sequentially with a pause between them.

        Args:
            batch: List of steps to execute
            context: Additional context for all steps
            results: Dictionary to store step results
        """
        original_sequential_mode = self.sequential_mode
        self.sequential_mode = True

        try:
            step_results = []
            for i, step in enumerate(batch, 1):
                logger.info(f"üìç Step {i}/{len(batch)}: {step.id}")
                try:
                    await self._execute_step_with_monitoring(step, context, results)
                    step_results.append(None)  # Success (result already in dict)
                except Exception as e:
                    logger.error(f"Step {step.id} failed: {e}")
                    step_results.append(e)

                # Pause between steps to avoid rate limiting
                if i < len(batch):
                    logger.info("‚è∏Ô∏è  Pausing 2s before next step...")
                    await asyncio.sleep(2)

            # Process results and handle errors
            self._process_step_results(batch, step_results, results)

        finally:
            # Restore original sequential mode
            self.sequential_mode = original_sequential_mode
    
    async def _execute_batch_concurrent(
        self,
        batch: List[Step],
        context: Optional[str],
        results: Dict[str, StepResult]
    ) -> None:
        """
        Execute a batch of steps concurrently using asyncio.gather().

        Args:
            batch: List of steps to execute
            context: Additional context for all steps
            results: Dictionary to store step results
        """
        # Create async tasks for each step
        tasks = [
            self._execute_step_with_monitoring(step, context, results)
            for step in batch
        ]

        # Execute all steps in parallel with asyncio.gather
        # return_exceptions=True allows other steps to continue if one fails
        step_results = await asyncio.gather(*tasks, return_exceptions=True)

        # Process results and handle errors
        self._process_step_results(batch, step_results, results)
    
    def _process_step_results(
        self,
        batch: List[Step],
        step_results: List[Any],
        results: Dict[str, StepResult]
    ) -> None:
        """
        Process the results of a batch of steps, handling errors and logging success/failure.

        Args:
            batch: List of steps that were executed
            step_results: List of results from asyncio.gather()
            results: Dictionary to store step results
        """
        for step, result in zip(batch, step_results):
            if isinstance(result, Exception):
                logger.error(f"Unexpected error executing step {step.id}: {result}")
                # Create failed result
                failed_result = StepResult(
                    step_id=step.id,
                    success=False,
                    output="",
                    tokens_used=0,
                    input_tokens=0,
                    output_tokens=0,
                    execution_time_ms=0,
                    error=str(result)
                )
                results[step.id] = failed_result
                self.metrics.record_step_result(step, failed_result)
                
                # Update monitor
                self.monitor.complete_step(
                    step.id,
                    False,
                    0.0,
                    0,
                    0.0,
                    str(result)
                )
            else:
                # Result is already stored in results dict by _execute_step_with_monitoring
                if result.success:
                    logger.info(f"‚úì Step {step.id} completed successfully")
                else:
                    logger.error(f"‚úó Step {step.id} failed: {result.error}")
    
    async def _execute_step_with_rate_limit(
        self,
        step: Step,
        context: Optional[str],
        results: Dict[str, StepResult],
        semaphore: asyncio.Semaphore
    ) -> StepResult:
        """
        Execute a step with rate limiting via semaphore.
        
        Args:
            step: Step to execute
            context: Additional context
            results: Dictionary to store results
            semaphore: Semaphore for rate limiting
            
        Returns:
            StepResult
        """
        async with semaphore:
            return await self._execute_step_with_monitoring(step, context, results)
    
    async def _execute_step_with_monitoring(
        self,
        step: Step,
        context: Optional[str],
        results: Dict[str, StepResult]
    ) -> StepResult:
        """
        Execute a single step with monitoring.
        
        This method encapsulates step execution with monitoring to facilitate parallelization.
        
        Args:
            step: Step to execute
            context: Additional context
            results: Dictionary to store step results
            
        Returns:
            StepResult with execution results
        """
        try:
            # Get provider info before execution
            provider_name = self.agent_router.select_provider_for_step(step)
            # #region agent log
            t_step = time.time(); _dbg("A", "orchestrator:step", "step start", {"step_id": step.id, "provider": provider_name})
            # #endregion
            # Start monitoring
            self.monitor.start_step(step.id, provider_name)
            self.monitor.update_step_progress(step.id, f"Executing with {provider_name}...")
            
            # Execute the step
            result = await self._execute_step(step, context, results)
            # #region agent log
            _dbg("A", "orchestrator:step", "step end", {"step_id": step.id, "duration_s": round(time.time() - t_step, 2), "success": result.success})
            # #endregion
            
            # Store result
            results[step.id] = result
            
            # Error survey: log step failure
            if not result.success:
                try:
                    from .core.error_survey import log_aetherflow_error
                    log_aetherflow_error(
                        title=f"Step {step.id} failed",
                        nature="step_failed",
                        proposed_solution="Re-run the step, adjust the plan, or fix the prompt.",
                        raw_error=result.error,
                        step_id=step.id,
                    )
                except Exception as survey_err:
                    logger.debug(f"Error survey log failed: {survey_err}")
            
            # Record metrics with provider info
            self.metrics.record_step_result(step, result, provider=provider_name)
            
            # Update monitor
            self.monitor.complete_step(
                step.id,
                result.success,
                result.execution_time_ms,
                result.tokens_used,
                result.cost_usd,
                result.error
            )
            
            return result
            
        except Exception as e:
            logger.error(f"Unexpected error executing step {step.id}: {e}")
            # Create failed result
            failed_result = StepResult(
                step_id=step.id,
                success=False,
                output="",
                tokens_used=0,
                input_tokens=0,
                output_tokens=0,
                execution_time_ms=0,
                error=str(e)
            )
            results[step.id] = failed_result
            self.metrics.record_step_result(step, failed_result)
            try:
                from .core.error_survey import log_aetherflow_error
                log_aetherflow_error(
                    title=f"Step {step.id} exception",
                    nature="step_exception",
                    proposed_solution="Check logs and fix the cause (prompt, provider, or code).",
                    raw_error=str(e),
                    step_id=step.id,
                )
            except Exception as survey_err:
                logger.debug(f"Error survey log failed: {survey_err}")
            # Update monitor
            self.monitor.complete_step(
                step.id,
                False,
                0.0,
                0,
                0.0,
                str(e)
            )
            return failed_result
    
    def _load_existing_files(self, step: Step) -> Dict[str, Optional[str]]:
        """
        Load existing file contents from step.context.get("files").
        
        Args:
            step: Step with context containing file paths
            
        Returns:
            Dictionary mapping file paths to their contents (or None if file doesn't exist)
        """
        files_content = {}
        
        # Get file paths from step context
        if not step.context or not isinstance(step.context, dict):
            return files_content
        
        file_paths = step.context.get("files", [])
        if not file_paths:
            return files_content
        
        # Limit number of files to avoid token overflow
        MAX_FILES_PER_STEP = 5
        if len(file_paths) > MAX_FILES_PER_STEP:
            logger.warning(
                f"Step {step.id} has {len(file_paths)} files, limiting to {MAX_FILES_PER_STEP} "
                f"(keeping first {MAX_FILES_PER_STEP})"
            )
            file_paths = file_paths[:MAX_FILES_PER_STEP]
        
        # Resolve project root (assuming orchestrator.py is in Backend/Prod/)
        project_root = Path(__file__).parent.parent.parent
        
        # Limit total size to avoid token overflow (~250k tokens ‚âà 1MB)
        MAX_TOTAL_SIZE = 1024 * 1024  # 1MB total
        MAX_FILE_SIZE = 200 * 1024  # 200KB per file
        total_size = 0
        
        for file_path_str in file_paths:
            try:
                # Resolve file path (relative or absolute)
                file_path = Path(file_path_str)
                if not file_path.is_absolute():
                    file_path = project_root / file_path
                
                # Normalize path
                file_path = file_path.resolve()
                
                # Check if file exists
                if not file_path.exists():
                    logger.debug(f"File not found (will be created): {file_path}")
                    files_content[file_path_str] = None
                    continue
                
                # Check if it's a file (not a directory)
                if not file_path.is_file():
                    logger.warning(f"Path is not a file: {file_path}")
                    files_content[file_path_str] = None
                    continue
                
                # Check file size
                file_size = file_path.stat().st_size
                if file_size > MAX_FILE_SIZE:
                    logger.warning(
                        f"File {file_path_str} is too large ({file_size} bytes > {MAX_FILE_SIZE} bytes). "
                        f"Will truncate to fit token limits."
                    )
                
                # Check total size limit
                if total_size + file_size > MAX_TOTAL_SIZE:
                    logger.warning(
                        f"Total file size limit reached ({total_size + file_size} bytes > {MAX_TOTAL_SIZE} bytes). "
                        f"Skipping remaining files."
                    )
                    break
                
                # Read file content
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                    
                    # Truncate if necessary (keep beginning and end)
                    if len(content.encode('utf-8')) > MAX_FILE_SIZE:
                        content_bytes = content.encode('utf-8')
                        # Keep first 160KB and last 40KB
                        keep_start = 160 * 1024
                        keep_end = 40 * 1024
                        if len(content_bytes) > keep_start + keep_end:
                            start_part = content_bytes[:keep_start].decode('utf-8', errors='ignore')
                            end_part = content_bytes[-keep_end:].decode('utf-8', errors='ignore')
                            content = f"{start_part}\n\n[... truncated {len(content_bytes) - keep_start - keep_end} bytes ...]\n\n{end_part}"
                            logger.info(f"Truncated file {file_path_str} to fit size limits")
                    
                    files_content[file_path_str] = content
                    total_size += len(content.encode('utf-8'))
                    logger.debug(f"Loaded file {file_path_str} ({len(content)} chars)")
                    
                except UnicodeDecodeError:
                    logger.warning(f"File {file_path_str} is not UTF-8 encoded, skipping")
                    files_content[file_path_str] = None
                except PermissionError:
                    logger.warning(f"Permission denied reading file {file_path_str}")
                    files_content[file_path_str] = None
                except Exception as e:
                    logger.warning(f"Error reading file {file_path_str}: {e}")
                    files_content[file_path_str] = None
                    
            except Exception as e:
                logger.warning(f"Error processing file path {file_path_str}: {e}")
                files_content[file_path_str] = None
        
        logger.info(f"Loaded {sum(1 for v in files_content.values() if v is not None)}/{len(file_paths)} existing files for step {step.id}")
        return files_content
    
    def _load_input_files(self, step: Step) -> Dict[str, Optional[str]]:
        """
        Load read-only file contents from step.context.get("input_files").
        Used for report/inventory tasks: inject genome, PRD, etc. without applying output to them.
        """
        files_content: Dict[str, Optional[str]] = {}
        if not step.context or not isinstance(step.context, dict):
            return files_content
        file_paths = step.context.get("input_files") or []
        if not file_paths:
            return files_content
        MAX_FILES = 5
        if len(file_paths) > MAX_FILES:
            logger.warning(f"Step {step.id} has {len(file_paths)} input_files, limiting to {MAX_FILES}")
            file_paths = file_paths[:MAX_FILES]
        project_root = Path(__file__).parent.parent.parent
        MAX_TOTAL_SIZE = 1024 * 1024  # 1MB
        MAX_FILE_SIZE = 200 * 1024  # 200KB per file
        total_size = 0
        for file_path_str in file_paths:
            try:
                file_path = Path(file_path_str)
                if not file_path.is_absolute():
                    file_path = project_root / file_path
                file_path = file_path.resolve()
                if not file_path.exists() or not file_path.is_file():
                    files_content[file_path_str] = None
                    continue
                file_size = file_path.stat().st_size
                if total_size + file_size > MAX_TOTAL_SIZE:
                    break
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                content_bytes = content.encode('utf-8')
                if len(content_bytes) > MAX_FILE_SIZE:
                    keep_start, keep_end = 160 * 1024, 40 * 1024
                    if len(content_bytes) > keep_start + keep_end:
                        content = content_bytes[:keep_start].decode('utf-8', errors='ignore') + "\n\n[... truncated ...]\n\n" + content_bytes[-keep_end:].decode('utf-8', errors='ignore')
                files_content[file_path_str] = content
                total_size += len(content.encode('utf-8'))
            except Exception as e:
                logger.warning(f"Error reading input_file {file_path_str}: {e}")
                files_content[file_path_str] = None
        if files_content:
            logger.info(f"Loaded {sum(1 for v in files_content.values() if v is not None)} input_files for step {step.id}")
        return files_content
    
    async def _execute_step(
        self,
        step: Step,
        context: Optional[str],
        previous_results: Dict[str, StepResult]
    ) -> StepResult:
        """
        Execute a single step.
        
        Args:
            step: Step to execute
            context: Additional context
            previous_results: Results from previous steps
            
        Returns:
            StepResult with execution results
        """
        # Build context from previous results if needed
        step_context = context or ""
        
        if step.dependencies:
            # Add outputs from dependent steps to context
            dep_outputs = []
            for dep_id in step.dependencies:
                if dep_id in previous_results:
                    dep_result = previous_results[dep_id]
                    if dep_result.success:
                        dep_outputs.append(f"Previous step {dep_id} output:\n{dep_result.output}")
            
            if dep_outputs:
                step_context = "\n\n".join([step_context] + dep_outputs) if step_context else "\n\n".join(dep_outputs)
        
        # Load input_files (read-only) and inject as reference data
        input_files = self._load_input_files(step)
        if input_files:
            ref_parts = ["\n\nReference data (read-only, do not modify):\n"]
            for path, content in input_files.items():
                if content is not None:
                    ref_parts.append(f"=== File: {path} ===\n{content}\n")
            step_context = "\n\n".join([step_context] + ref_parts) if step_context else "".join(ref_parts)
        
        # Load existing files and inject into context
        existing_files = self._load_existing_files(step)
        surgical_mode = False
        ast_contexts = {}

        if existing_files:
            # Check if surgical mode should be activated
            # Surgical mode: enabled by default for refactoring/code_generation, or explicitly via step.context
            project_root = Path(__file__).parent.parent.parent

            # First, check if we have any Python files that exist AND have content
            has_python_files = False
            has_existing_code = False
            for file_path_str, content in existing_files.items():
                if content is not None and len(content.strip()) > 0:
                    # File exists and has content
                    has_existing_code = True
                    file_path = Path(file_path_str)
                    if not file_path.is_absolute():
                        file_path = project_root / file_path
                    if file_path.suffix == '.py' and file_path.exists():
                        has_python_files = True
                        break

            # Surgical mode: ONLY if files exist with content
            # Disabled for new files (content is None or empty)
            surgical_mode = has_existing_code and (
                step.context.get('surgical_mode', True) or (