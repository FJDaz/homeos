"""
Models for CodeReviewAgent - Implementation Plan and Review Report.

Pydantic models for structured validation of implementation plans.
"""

from enum import Enum
from typing import Dict, Any, List, Optional
from pydantic import BaseModel, Field, validator


class ValidationResult(Enum):
    """Validation result status."""
    APPROVED = "approved"
    WARNINGS = "warnings"
    REJECTED = "rejected"


class AetherFlowMode(str, Enum):
    """
    Modes AetherFlow disponibles.
    
    - PROTO : Rapide, POC, utilitaires (-q)
    - PROD : Production, Surgical Edit (-f)
    - SURGICAL : Modification précise de fichiers existants
    """
    PROTO = "proto"       # -q / --quick
    PROD = "prod"         # -f / --full
    SURGICAL = "surgical" # Modification précise


class ImplementationPlan(BaseModel):
    """
    Structured implementation plan submitted for review.
    
    Attributes:
        module_cible: Target module for implementation
        fichiers_modifies: List of files to be modified
        fichiers_crees: List of files to be created
        mode_aetherflow: AetherFlow mode to use (Enum)
        outils_sullivan_utilises: List of Sullivan tools to use
        description: Description of the implementation
        etapes: List of implementation steps
        risques_identifies: List of identified risks
        tests_recommandes: List of recommended tests
        dependances: List of dependencies
        z_index_layers: Z-index layers used (for HomeOS modes)
        known_attention_points: Known attention points from STATUS_REPORT
    """
    
    module_cible: str = Field(..., description="Target module for implementation")
    fichiers_modifies: List[str] = Field(default_factory=list, description="Files to modify")
    fichiers_crees: List[str] = Field(default_factory=list, description="Files to create")
    mode_aetherflow: AetherFlowMode = Field(
        ..., 
        description="Mode AetherFlow à utiliser (proto, prod, surgical)"
    )
    outils_sullivan_utilises: List[str] = Field(
        default_factory=list, 
        description="Sullivan tools to use"
    )
    description: str = Field(..., description="Implementation description")
    etapes: List[str] = Field(default_factory=list, description="Implementation steps")
    risques_identifies: List[str] = Field(
        default_factory=list, 
        description="Identified risks"
    )
    tests_recommandes: List[str] = Field(
        default_factory=list, 
        description="Recommended tests"
    )
    dependances: List[str] = Field(default_factory=list, description="Dependencies")
    z_index_layers: Optional[List[str]] = Field(
        None, 
        description="Couches z-index utilisées (selon construction_config.yaml ou project_config.yaml)"
    )
    known_attention_points: Optional[List[str]] = Field(
        default_factory=list,
        description="Points d'attention identifiés dans STATUS_REPORT_HOMEOS.md"
    )
    
    @validator('mode_aetherflow', pre=True)
    def validate_aetherflow_mode(cls, v):
        """Validate AetherFlow mode - case insensitive."""
        if isinstance(v, AetherFlowMode):
            return v
        valid_modes = ['proto', 'prod', 'surgical', '-q', '-f']
        v_str = str(v).lower().replace('-', '')
        # Mapper les flags courts
        if v_str == 'q':
            v_str = 'proto'
        elif v_str == 'f':
            v_str = 'prod'
        
        if v_str not in valid_modes:
            raise ValueError(f"Mode AetherFlow invalide: '{v}'. Doit être: proto, prod, surgical")
        return AetherFlowMode(v_str)
    
    @validator('z_index_layers')
    def validate_z_index(cls, v):
        """Validate z-index layers if provided."""
        if v is None:
            return v
        valid_layers = ['background', 'content', 'overlay', 'modal', 'notification', 'system']
        for layer in v:
            if layer not in valid_layers:
                raise ValueError(f"Couche z-index invalide: '{layer}'. Valide: {valid_layers}")
        return v


class RuleViolation(BaseModel):
    """Single rule violation found during review."""
    
    rule_name: str = Field(..., description="Name of the violated rule")
    severity: str = Field(..., description="Severity: error, warning, info")
    message: str = Field(..., description="Human-readable description")
    suggestion: Optional[str] = Field(None, description="Suggested fix")
    fichier_concerne: Optional[str] = Field(None, description="Affected file")


class ReviewReport(BaseModel):
    """
    Report generated by CodeReviewAgent after analyzing a plan.
    
    Attributes:
        plan: The original implementation plan
        result: Validation result (APPROVED, WARNINGS, REJECTED)
        violations: List of rule violations
        suggestions: General suggestions for improvement
        score: Validation score (0-100)
        reviewed_at: Timestamp of review
    """
    
    plan: ImplementationPlan = Field(..., description="Original plan")
    result: ValidationResult = Field(..., description="Validation result")
    violations: List[RuleViolation] = Field(
        default_factory=list, 
        description="Rule violations"
    )
    suggestions: List[str] = Field(
        default_factory=list, 
        description="General suggestions"
    )
    score: int = Field(..., ge=0, le=100, description="Validation score 0-100")
    reviewed_at: str = Field(..., description="Review timestamp")
    
    def is_approved(self) -> bool:
        """Check if plan is approved."""
        return self.result == ValidationResult.APPROVED
    
    def has_errors(self) -> bool:
        """Check if report contains errors."""
        return any(v.severity == "error" for v in self.violations)
    
    def has_warnings(self) -> bool:
        """Check if report contains warnings."""
        return any(v.severity == "warning" for v in self.violations)
    
    def to_dict(self) -> Dict[str, Any]:
        """Export report to dictionary."""
        return {
            "plan": self.plan.dict(),
            "result": self.result.value,
            "violations": [v.dict() for v in self.violations],
            "suggestions": self.suggestions,
            "score": self.score,
            "reviewed_at": self.reviewed_at,
            "approved": self.is_approved(),
        }


class ValidationRules(BaseModel):
    """Configuration for validation rules."""
    
    # Architecture rules
    require_module_check: bool = True
    require_existing_tool_check: bool = True
    require_homeos_pattern: bool = True
    
    # Mode validation
    validate_mode_selection: bool = True
    require_prod_for_existing_files: bool = True
    
    # Risk management
    max_risks_allowed: int = 5
    require_tests_for_complexity: bool = True
    
    # Sullivan-specific
    check_singleton_preservation: bool = True
    check_z_index_compliance: bool = True
    check_memory_preservation: bool = True


# Pre-defined validation rule templates
RULE_TEMPLATES = {
    "missing_status_report_check": {
        "rule_name": "Status Report Not Consulted",
        "severity": "warning",
        "message": "STATUS_REPORT_HOMEOS.md not mentioned in plan context",
        "suggestion": "Always check docs/04-homeos/STATUS_REPORT_HOMEOS.md first",
    },
    "existing_tool_not_used": {
        "rule_name": "Existing Tool Not Used",
        "severity": "error",
        "message": "An existing Sullivan tool could be used instead",
        "suggestion": "Check Backend/Prod/sullivan/ for existing tools",
    },
    "singleton_violation": {
        "rule_name": "Singleton Pattern Violation",
        "severity": "error",
        "message": "Plan may break singleton pattern (ModeManager, etc.)",
        "suggestion": "Ensure singleton instances are preserved",
    },
    "z_index_violation": {
        "rule_name": "Z-Index Layer Violation",
        "severity": "warning",
        "message": "Z-index values may conflict with mode requirements",
        "suggestion": "Check homeos/config/construction_config.yaml for z-index layers",
    },
    "missing_tests": {
        "rule_name": "No Tests Recommended",
        "severity": "warning",
        "message": "Plan does not include recommended tests",
        "suggestion": "Add tests for critical functionality",
    },
    "wrong_mode": {
        "rule_name": "Inappropriate AetherFlow Mode",
        "severity": "error",
        "message": "Mode selection may not be appropriate for task",
        "suggestion": "Use PROD (-f) for file modifications, PROTO (-q) for utilities",
    },
}


__all__ = [
    "ValidationResult",
    "AetherFlowMode",
    "ImplementationPlan",
    "RuleViolation",
    "ReviewReport",
    "ValidationRules",
    "RULE_TEMPLATES",
]
